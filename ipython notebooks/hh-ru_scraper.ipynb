{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for visualizing skills as a graph\n",
    "\n",
    "You may run all cells to test. It will take near one minute to scrape data and show the graph.\n",
    "\n",
    "Set SEARCH_WORD to scrape and visualize tags by your word search results. \n",
    "\n",
    "It may take up to 10 minutes to scrape all vacancies so please be patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import itertools\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting all pages with vacancies found by word from hh.ru\n",
    "\n",
    "SERCH_WORD = 'python hadoop'  # word or phrase to search in vacancies\n",
    "\n",
    "\n",
    "ses = requests.Session()\n",
    "ses.headers = {'HH-User-Agent': \"Mozilla/5.0 (X11; Linux x86_64; rv:10.0) Gecko/20100101 Firefox/10.0\"}\n",
    "\n",
    "url = f'https://api.hh.ru/vacancies?text={SERCH_WORD}&per_page=100'\n",
    "res = ses.get(url)\n",
    "\n",
    "res_all = []\n",
    "for p in range(res.json()['pages']):\n",
    "    print(f'scraping page {p}')\n",
    "    p_url = url + f'&page={p}'\n",
    "    res = ses.get(p_url)\n",
    "    res_all.append(res.json())\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# parcing vacancies ids, getting vacancy responce and scraping tags from each vacancy\n",
    "\n",
    "tags_list = []\n",
    "\n",
    "for page_res_json in res_all:\n",
    "    for i in range(len(page_res_json['items'])):\n",
    "        vac_id = page_res_json['items'][i]['id']\n",
    "        vac_res = ses.get(f'https://api.hh.ru/vacancies/{vac_id}')\n",
    "\n",
    "        if len(vac_res.json()[\"key_skills\"]) > 0:  # at least one skill present\n",
    "            print(vac_id)\n",
    "            tags = [v for v_dict in vac_res.json()[\"key_skills\"] for _, v in v_dict.items()]\n",
    "            print(' '.join(tags))\n",
    "            tags_list.append(tags)\n",
    "            print()\n",
    "\n",
    "        time.sleep(0.1)  # not to overload server "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flattened_list = [i for line in tags_list for i in line]\n",
    "\n",
    "# some filtering by occurences count\n",
    "# YOU CAN TURN IT OFF\n",
    "flattened_list = [x for x in flattened_list if flattened_list.count(x) > 10]\n",
    "\n",
    "# counting words occurences\n",
    "words_count = {i:flattened_list.count(i) for i in set(flattened_list)}\n",
    "print('Tags count:')\n",
    "print('\\n'.join(\n",
    "    [f'- {k}: {v}' for k, v in sorted(words_count.items(), key=lambda x: x[1], reverse=True)]))\n",
    "\n",
    "\n",
    "# tags connection dict initialization\n",
    "formatted_tags = {}\n",
    "for tag1 in set(flattened_list):\n",
    "    for tag2 in set(flattened_list):\n",
    "        formatted_tags[(tag1, tag2)] = 0 \n",
    "\n",
    "        \n",
    "# count tags connection\n",
    "for line in tags_list:\n",
    "    for tag1, tag2 in itertools.product(line, repeat=2):\n",
    "        if (tag1, tag2) in formatted_tags:\n",
    "            formatted_tags[(tag1, tag2)] += 1 \n",
    "            \n",
    "            \n",
    "# filtering data from zero occurances\n",
    "for k, v in formatted_tags.copy().items():\n",
    "    if v == 0 or k[0] == k[1]:\n",
    "        del formatted_tags[k]\n",
    "            \n",
    "print('\\nTag to tag frequency:')\n",
    "for k,v in sorted(formatted_tags.items(), key=lambda x: x[1], reverse=True):\n",
    "    print('-', k,v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save results\n",
    "\n",
    "with open('formatted_tags.pkl', 'wb') as f:\n",
    "    pickle.dump(formatted_tags, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# build and show graph\n",
    "\n",
    "G=nx.Graph()\n",
    "\n",
    "G.add_edges_from(list(formatted_tags.keys()))\n",
    "pos = nx.spring_layout(G, k=0.5, iterations=200)\n",
    "e_widths = [i/3 for i in formatted_tags.values()]  # edge size\n",
    "n_widths = [words_count[i]*100 for i in list(G.nodes())]  # node size\n",
    "\n",
    "f = plt.figure(figsize=(32,32))\n",
    "\n",
    "nx.draw_networkx_nodes(G, pos, node_color='#A0CBE2', node_size=n_widths, node_cmap=plt.cm.Blues)\n",
    "nx.draw_networkx_edges(G, pos, edge_color='#C0CBD2', edgelist=list(formatted_tags.keys()), width=e_widths, edge_cmap=plt.cm.Blues)\n",
    "nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save graph as picture file\n",
    "\n",
    "f.savefig(\"tags_graph.png\", format=\"PNG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
